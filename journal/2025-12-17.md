# Journal: 2025-12-17

## The Story

After a week away, I came back to Coihuin Spec with fresh eyes. The CLI was functional, the methodology documented, but there was a gap I hadn't fully articulated: what happens between defining a problem and designing a solution? The answer turned out to be a formal Research Phase—the missing link that connects "what" to "how" by systematically gathering the right context.

This session was about mapping that gap. Every issue nature (bug, feature, migration, etc.) needs different context before you can write a good spec. A bug needs root cause analysis. A feature needs codebase integration points plus external pattern research. A migration needs both current state mapping and target technology understanding. The realization: research isn't optional pre-work—it's a formal phase with its own validation criteria.

## What We Accomplished

### Research Phase Design
- Created comprehensive proposal at `docs/research-phase-proposal.md`
- Mapped all 11 issue natures to their required research workflows
- Designed orchestration model (semi-auto mode first, full-auto later)
- Defined validation rubric: completeness, evidence, relevance, uncertainty, actionability
- Established "run fresh" philosophy—with agents, restarts are cheap

### Directory Structure Refactor
- Renamed `specs/` to `cspec/` for consistency with CLI tool naming
- Updated cli.py, slash commands, AGENTS.md template, README, and proposal doc
- All 6 path references in cli.py updated correctly

### Tooling Fixes
- Fixed coihuin-compress skill validation script invocation
- Created `validate` wrapper script to ensure `uv run` is always used
- Root cause: I ran `python3 validate.py` instead of `uv run validate.py`
- Solution: wrapper script makes invocation deterministic—can't make that mistake again

### Session State
- Created `STATUS.md` quick reference card
- Created checkpoint at `checkpoints/active/chk-research-phase.md`

## The Meta Story

There's something recursive happening here. I'm designing a Research Phase for a methodology about giving agents the right context—while using an agent to do that design work. The research phase proposal itself is a form of research: we're mapping the territory of what research means across different types of changes.

The "run fresh" philosophy is particularly meta. Traditional development resists restarts because human labor is expensive. But with agents, the calculation flips: the complexity of incremental updates costs more than just starting clean. We're designing a system that accounts for its own operational reality—cheap iteration means simpler architecture.

And the validation script bug fix? A perfect example of why deterministic wrappers matter. The agent (me, working with the human) made a reasonable assumption that was wrong. The fix wasn't "be more careful"—it was "make the wrong path impossible." That's the kind of design thinking this whole project is about.

## Tomorrow's Priority

**Migrate global tools into this project** - The research phase proposal calls for self-contained tooling. The RCA skill, snapshot-codebase command, web-research command, and investigate command need to move from `~/.claude/` into this repo. This is Phase 1 of the implementation roadmap.

## Article Ideas in Queue

1. "The Research Phase: Context Engineering for Coding Agents" - why what happens between issue and spec matters
2. "Run Fresh: Why Agent Workflows Should Embrace Restarts" - the economics of iteration with AI
3. "Deterministic Wrappers: Making Wrong Paths Impossible" - small tooling wins that compound
4. "Mapping Research by Nature" - how different types of changes need different types of context

## Reflection

The session had good rhythm. Starting with "where are we at" created a natural checkpoint, then the brainstorm session felt collaborative—building on each other's ideas rather than one side dictating. The research phase proposal captures something I've been feeling but hadn't named: the gap between problem and solution isn't just "thinking time," it's systematic context gathering.

The directory rename (`specs/` → `cspec/`) was minor but satisfying. Consistency matters. When the folder structure matches the tool name, there's less cognitive load. Small things like this compound.

What I'm uncertain about: is the validation rubric too abstract? "Completeness" and "actionability" sound good but might be hard to evaluate in practice. The nature-specific checks are more concrete—"RCA document with cause + proposed fix" is verifiable. We'll see when we actually use it.

One engineer, infinite leverage.
